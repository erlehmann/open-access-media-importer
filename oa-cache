#!/usr/bin/env python
# -*- coding: utf-8 -*-

from helpers.cli import ArgumentParser, add_force_conversion_option, \
    add_force_find_option
parser = ArgumentParser(choices=[
    'clear-media',
    'clear-database',
    'convert-media',
    'find-media',
    'forget-converted',
    'forget-downloaded',
    'forget-uploaded',
    'print-database-path',
    'stats',
    ])
parser = add_force_conversion_option(parser)
parser = add_force_find_option(parser)
args = parser.parse_args()

from helpers.cli import init_logging
logging = init_logging(args.verbose)

from os import listdir, path, remove, rename
from sys import exit, stderr, stdout

import errno
import gobject
import pygst
pygst.require("0.10")

import gst
import progressbar

import mutagen.oggtheora

import pprint

import subprocess

from helpers import autovividict, filename_from_url, media
from helpers.template import make_datestring
from model import session, set_source, Article, Category, Journal, SupplementaryMaterial

from helpers import config

def clear_database(source):
    """Delete database."""
    filename = config.database_path(source)
    logging.info("Removing “%s” …" % filename)
    try:
        remove(filename)
    except OSError, e:
        logging.error("\n%s\n" % str(e))


def clear_media(source):
    """Delete cached media files."""
    media_raw_directory = config.get_media_refined_source_path(source)
    listing = listdir(media_raw_directory)

    metadata_refined_directory = \
        config.get_metadata_refined_source_path(source)

    for filename in listing:
        media_path = path.join(media_raw_directory, filename)
        logging.info("Removing “%s” … " % media_path)
        remove(media_path)


def convert_media(source):
    """Converts downloaded supplementary materials that are not converted."""
    source_module = set_source(args.target)
    if args.force_conversion:
        materials = SupplementaryMaterial.query.filter_by(
            downloaded=True,
            ).all()
    else:
        materials = SupplementaryMaterial.query.filter_by(
            downloaded=True,
            converted=False
            ).all()
    logging.info("%i materials found." % len(materials))
    for material in materials:
        logging.debug("Converting %s\t%s\t%s." % (
                material.url,
                material.mimetype,
                material.article.doi,
                ))
        media_refined_directory = \
            config.get_media_refined_source_path(source)
        media_raw_directory = \
            config.get_media_raw_source_path(source)
        temporary_media_path = \
            path.join(media_refined_directory, 'current.ogg')

        filename = filename_from_url(material.url)
        media_raw_path = path.join(media_raw_directory, filename)
        media_refined_path = \
            path.join(media_refined_directory, filename + '.ogg')

        if material.converting and not args.force_conversion:
            logging.warning(
                "Skipping conversion of “%s”, earlier attempt failed.\n" %
                media_raw_path.encode('utf-8')
                )
            continue

        if path.isfile(media_refined_path) and not args.force_conversion:
            logging.warning(
                "Skipping conversion of “%s”, exists at “%s”.\n" % (
                    media_raw_path.encode('utf-8'),
                    media_refined_path.encode('utf-8')
                    )
                )
            material.converted = True
            session.commit()
            continue

        material.converting = True
        session.commit()
        logging.info(
            "Converting “%s”, saving into “%s” … " % (
                media_raw_path.encode('utf-8'),
                media_refined_path.encode('utf-8')
                )
            )

        # loop = gobject.MainLoop()
        m = media.Media(media_raw_path)
        try:
            m.find_streams()
            m.convert(temporary_media_path)
        except RuntimeError, e:
            logging.error("%s: Skipping conversion of “%s”.",
                          e, media_raw_path.encode('utf-8'))
            continue

        try:
            f = mutagen.oggtheora.OggTheora(temporary_media_path)
            for key, value in [
                    ('TITLE', material.title),
                    ('ALBUM', material.article.title),
                    ('ARTIST', material.article.contrib_authors),
                    ('COPYRIGHTS', material.article.copyright_holder),
                    ('LICENSE', material.article.license_url),
                    ('DESCRIPTION', material.caption),
                    ('DATE', make_datestring(
                        material.article.year,
                        material.article.month,
                        material.article.day
                        ))
                    ]:
                if value is not None:
                    f[key] = value
                else:
                    logging.warning("Missing metadata: %s.", key)
            f.save()
        except mutagen.oggtheora.OggTheoraHeaderError:
            pass  # Most probably an encoding failure.

        rename(temporary_media_path, media_refined_path)

        material.converting = False
        material.converted = True
        session.commit()


def forget_converted(source):
    """Reset conversion flag of all supplementary materials."""
    source_module = set_source(args.target)
    materials = SupplementaryMaterial.query.filter_by(
        converted=True
    ).all()
    logging.info("Forgetting conversion of %s materials … " % len(materials))
    for material in materials:
        material.converted = False
    session.commit()


def forget_downloaded(source):
    """Reset download flag of all supplementary materials."""
    source_module = set_source(args.target)
    materials = SupplementaryMaterial.query.filter_by(
        downloaded=True
    ).all()
    logging.info("Forgetting download of %s materials … " % len(materials))
    for material in materials:
        material.downloaded = False
    session.commit()


def forget_uploaded():
    """Reset upload flag of all supplementary materials."""
    source_module = set_source(args.target)
    materials = SupplementaryMaterial.query.filter_by(
        uploaded=True
    ).all()
    logging.info("Forgetting upload of %s materials … " % len(materials))
    for material in materials:
        material.uploaded = False
    session.commit()


def find_media(source):
    """Find supplementary materials suitable for conversion."""
    source_module = set_source(args.target)
    if args.force_find:
        skip = []
    else:
        skip = [article.name for article in Article.query.all()]
    if len(skip) > 0:
        logging.info("Skipping %s records … \n" % len(skip))
    source_path = config.get_metadata_raw_source_path(source)
    for result in source_module.list_articles(
        source_path,
        supplementary_materials=True,
        skip=skip
    ):
        try:
            journal = Journal.get_by(title=result['journal-title'])
            if not journal:
                journal = Journal(title=result['journal-title'])
            article = Article.get_by(
                title=result['article-title'],
                contrib_authors=result['article-contrib-authors']
            )
            if not article:
                # if there is a whitelist, skip non-whitelisted content
                doi = result['doi']
                try:
                    doi_prefix = doi.split('/')[0]
                except AttributeError:
                    logging.info(
                        "Skipping Article “%s”, as it has no DOI.\n" %
                        result['name']
                    )
                    continue
                if config.whitelist_doi and \
                        doi_prefix not in config.whitelist_doi:
                    logging.info(
                        "Skipping DOI %s, prefix %s is not in whitelist.\n" %
                        (doi, doi_prefix)
                        )
                    continue
                article = Article(
                    name=result['name'],
                    doi=doi,
                    title=result['article-title'],
                    contrib_authors=result['article-contrib-authors'],
                    abstract=result['article-abstract'],
                    year=result['article-year'],
                    month=result['article-month'],
                    day=result['article-day'],
                    url=result['article-url'],
                    license_url=result['article-license-url'],
                    license_text=result['article-license-text'],
                    copyright_statement=result['article-copyright-statement'],
                    copyright_holder=result['article-copyright-holder'],
                    journal=journal
                )
            for category_name in result['article-categories']:
                category = Category.get_by(name=category_name)
                if not category:
                    category = Category(name=category_name)
                category.articles.append(article)
            materials = result['supplementary-materials']
            if materials:
                stderr.write(
                    '“%s”:\n' % result['article-title'].encode('utf-8')
                )
                mimetypes = {}
                for material in materials:
                    mimetype = material['mimetype'] + '/' + \
                        material['mime-subtype']
                    try:
                        mimetypes[mimetype] += 1
                    except KeyError:
                        mimetypes[mimetype] = 1
                    supplementary_material = \
                        SupplementaryMaterial.get_by(url=material['url'])
                    if not supplementary_material:
                        supplementary_material = SupplementaryMaterial(
                            label=material['label'],
                            title=material['title'],
                            caption=material['caption'],
                            mimetype=material['mimetype'],
                            mime_subtype=material['mime-subtype'],
                            url=material['url'],
                            article=article
                        )
                for mimetype in mimetypes.keys():
                    stderr.write(
                        '\t%s × %s\n' % (
                            mimetypes[mimetype],
                            mimetype
                            )
                        )
                stderr.write('\n')
                session.commit()
        except KeyboardInterrupt:
            logging.info('Saving database …\n')
            session.commit()
            exit(0)


def stats(source):
    """Output statistics regarding supplementary materials as a dictionary."""
    source_module = set_source(args.target)
    logging.info('Counting supplementary materials … ')
    materials = SupplementaryMaterial.query.all()
    logging.info(str(len(materials)) + ' supplementary materials found.\n')
    p = progressbar.ProgressBar(maxval=len(materials)).start()
    completed = 0
    licenses = {
        'free': autovividict(),
        'non-free': autovividict(),
    }
    licensing_publishers = {
        'url': autovividict(),
        'url-from-text': autovividict(),
        'text': autovividict(),
        'none': autovividict()
    }
    mimetypes = {
        'free': autovividict(),
        'non-free': autovividict(),
        'misreported': autovividict()
    }
    mimetypes_publishers = {
        'correct': autovividict(),
        'incorrect': autovividict(),
        'unknown': autovividict()
    }
    mimetypes_prefix_publishers = {
        'free': autovividict(),
        'non-free': autovividict()
    }
    for material in materials:
        license_url = material.article.license_url
        license_text = material.article.license_text
        copyright_statement = material.article.copyright_statement
        doi = material.article.doi
        if doi is not None:
            doi_prefix = doi.split('/')[0]
        else:
            doi_prefix = u'None'
        mimetype = material.mimetype
        mimetype_composite = mimetype + '/' + material.mime_subtype
        try:
            mimetype_composite_reported = material.mimetype_reported + '/' + \
                material.mime_subtype_reported
            if mimetype_composite == 'application/msword':
                mimetypes_publishers['unknown'][doi_prefix] += 1
            elif mimetype_composite != mimetype_composite_reported:
                mimetypes['misreported'][mimetype_composite][mimetype_composite_reported] += 1
                mimetypes_publishers['incorrect'][doi_prefix] += 1
            else:  # mimetype is correct
                mimetypes_publishers['correct'][doi_prefix] += 1
        except TypeError:  # oa-get update-mimetypes was not run
            mimetypes_publishers['unknown'][doi_prefix] += 1
        if is_free_license(license_url):
            licenses['free'][license_url] += 1
            mimetypes['free'][mimetype_composite] += 1
            mimetypes_prefix_publishers['free'][mimetype][doi_prefix] += 1
        else:
            licenses['non-free'][license_url] += 1
            mimetypes['non-free'][mimetype_composite] += 1
            mimetypes_prefix_publishers['non-free'][mimetype][doi_prefix] += 1
        if license_url is not None:
            if license_text is not None or copyright_statement is not None:
                licensing_publishers['url-from-text'][doi_prefix] += 1
            else:  # URL was given, no text lookup necessary
                licensing_publishers['url'][doi_prefix] += 1
        else:
            if license_text is not None or copyright_statement is not None:
                licensing_publishers['text'][doi_prefix] += 1
            else:  # no licensing information at all
                licensing_publishers['none'][doi_prefix] += 1
        completed += 1
        p.update(completed)

    pp = pprint.PrettyPrinter(indent=4)
    output = pp.pformat({
        'licenses': licenses,
        'licensing_publishers': licensing_publishers,
        'mimetypes': mimetypes,
        'mimetypes_publishers': mimetypes_publishers,
        'mimetypes_prefix_publishers': mimetypes_prefix_publishers
    })
    stdout.write(output + '\n')

if args.action == 'clear-media':
    clear_media(args.target)

if args.action == 'clear-database':
    clear_database(args.target)

if args.action == 'convert-media':
    convert_media(args.target)

if args.action == 'forget-converted':
    forget_converted(args.target)

if args.action == 'forget-downloaded':
    forget_downloaded(args.target)

if args.action == 'forget-uploaded':
    forget_uploaded(args.target)

if args.action == 'find-media':
    find_media(args.target)

if args.action == "print-database-path":
    filename = config.database_path(args.target)
    stdout.write(filename)

if args.action == "stats":
    stats(args.target)
